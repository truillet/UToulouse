

Travaux Pratiques

Interaction Vocale

(Ph. Truillet)

Septembre 2023

# 1. Une application dirigÃ©e Ã  la voix

![RÃƒÂ©sultat de recherche d'images pour "assiette gourmande"](data:image/jpeg;base64...)Nous souhaitons concevoir et rÃ©aliser une application **non-visuelle** (en **entrÃ©e** et en **sortie** incluant **parole** et Ã©ventuellement **son -**musique, messages enregistrÃ©s, etc.) permettant Ã  un utilisateur **dâ€™ajouter, retirer, manipuler des aliments et boissons affichÃ©s sur un Ã©cran afin de composer le contenu dâ€™une assiette Â«Â gourmandeÂ Â».** (exÂ : cafÃ©, thÃ©, jus dâ€™orange, crÃ¨me brÃ»lÃ©e, profiteroles, â€¦ ). Il y a aura exactement **deux** desserts et **une** boisson dans le plat composÃ©.

**La disposition physique des desserts fait partie du problÃ¨meÂ !**

Vous coderez **votre application dans le langage que vous dÃ©sirez â˜º** (lâ€™usage de *Processing.org* peut Ãªtre une bonne alternative).

**Il devra Ãªtre possible dâ€™effectuer toutes les actions demandÃ©es de maniÃ¨re purement vocale en entrÃ©e et en sortie.**

Afin de rÃ©aliser notre application multimÃ©dia, **nous nous servirons prioritairement du middleware** (bus logiciel) **ivy**  [https://github.com/truillet/ivy/blob/master/README.md], support au futur Bureau dâ€™Etudes sur la multimodalitÃ©.

**Nota**Â : Si vous Ãªtes sous Linux ou MacOS, il vous faudra trouver des solutions alternatives pour la reconnaissance et la synthÃ¨se vocale (par exemple, utiliser **MaryTTS, ElevenIO** pour la synthÃ¨se vocale ou **STT** ou encore **SpeechRecognition**, librairie python pour la reconnaissance vocale â€“ cf. liens plus bas).

# 2. Travail attendu de cette sÃ©ance (2 h)

AprÃ¨s avoir pris en main les agents de reconnaissance et de synthÃ¨se vocale fonctionnant avec le bus logiciel ivy, lâ€™objet de cette sÃ©ance estÂ :

1. de **dÃ©finir la grammaire de reconnaissance** (commandes vocales ou langage Â«Â *pseudo-naturel*Â Â») qui sera utilisÃ©e par votre application, gÃ©rer les rÃ©sultats de la sortie sÃ©mantique (i.e. les concepts associÃ©s aux paroles prononcÃ©es) ainsi que le taux de confiance.
2. de **dÃ©finir les retours (feedbacks) vocaux Ã  synthÃ©tiser et** sonores utilisÃ©s par votre application.
3. de dÃ©velopper une application dâ€™affichage des plats Ã  lâ€™Ã©cran (en java, Processing, python â€¦ ou un autre langage).
4. et enfin **dÃ©velopper le contrÃ´leur de dialogue** Ã  **lâ€™aide dâ€™une machine Ã  Ã©tats** (qui peut Ãªtre soit sÃ©parÃ©e, soit incluse dans lâ€™application dâ€™affichage de la forme). Le contrÃ´leur sâ€™appuiera sur un Ã©change de messages ivy avec au moins les modules de reconnaissance et de synthÃ¨se vocale.

A la fin de la sÃ©ance, vous aurez produit **un prototype haute-fidÃ©litÃ© testable** du systÃ¨me demandÃ©.

**Nota**Â : pour ce faire, vous pourrez utiliser quelques agents ivy dÃ©jÃ  codÃ©s (prÃ©sentÃ©s en annexe)

# 3. Liens de tÃ©lÃ©chargements

* **ppilot5** (Text-to-Speech), **sra5** (Automatic Speech Recognition), **â€¦** agents dâ€™interaction vocale
  https://github.com/truillet/upssitech/tree/master/SRI/3A/IHM
* **librairies ivyÂ :**https://github.com/truillet/ivy/blob/master/README.md
* Si vous le dÃ©sirez, vous pouvez aussi utiliserÂ :
  + **MaryTTS** (https://github.com/marytts/marytts), serveur Test-to-Speech Ã©crit en Java
  + **ElevenIO (**https://elevenlabs.io**),** TTS accessible via une API REST (https://api.elevenlabs.io/docs)
* **STT**Â : Speech Recognition for Java/Processing basÃ© sur Google Chrome et websockets : http://florianschulz.info/stt
  **Nota**Â : Vous pouvez utiliser la page https://www.irit.fr/~Philippe.Truillet/stt.html pour lancer le serveur de reconnaissance.
* **SpeechRecognition**, librairie en PythonÂ : https://pythonprogramminglanguage.com/speech-recognition/

Nâ€™hÃ©sitez pas Ã  demander Ã  lâ€™enseignant si tel ou tel agent existeÂ : câ€™est peut-Ãªtre dÃ©jÃ  le casÂ ! Et puis, vous pouvez **CODER** vos propres agents selon **VOS** dÃ©sirsÂ !â˜º

# Annexe 1 - utiliser sra5

**sra5** est un agent utilisant le moteur de reconnaissance natif SAPI 5.x de Windows Vista, 7, 8.1,10 et 11 et peut renvoyer **deux types de solutions** issues de la reconnaissance **sous deux formats diffÃ©rents**Â :

**Lancement de lâ€™agent en ligne de commandes**

sra5 -b 127.255.255.255:2010 â€“p on -g grammaire.grxml

**Par dÃ©faut, sra5 utilise le fichier de grammaire locale grammaire.grxml**

**-b** adresse IP + port

**-p** mode de renvoi des donnÃ©es (mode parsage1 **on** ou **off**)

**-g** fichier de grammaire utilisÃ© (grammaire de type grXML
 â€“ cf. http://www.w3.org/TR/speech-grammar)

*1 Le mode Â«Â parsageÂ Â» consiste Ã  renvoyer comme rÃ©sultat les sorties sÃ©mantiques plutÃ´t que la chaÃ®ne orthographique.*

**Retours (UNIQUEMENT sur le bus ivy)**

* **sra5 Text=**chaÃ®ne\_orthographique **Confidence=**taux\_de\_confiance (si le flag *parse* est positionnÃ© Ã  off)
* **sra5 Parsed=**resultat **Confidence=**taux\_de\_confiance **NP=**xx **Num\_A=**xx oÃ¹ NP est le numÃ©ro du rÃ©sultat courant et Num\_A le numÃ©ro dâ€™alternative (si le flag *parse* est positionnÃ© Ã  on)
* **sra5 Event=**{Grammar\_Loaded | Speech\_Rejected} : envoi dâ€™Ã©vÃ©nements provenant du moteur de reconnaissance.

**Commandes (UNIQUEMENT sur le bus ivy)**

* **sra5 -p** {on | off} sra5 change le mode de retour de la reconnaissance (*on* ğŸ¡ª mode de retour sous forme de concept ou *off* ğŸ¡ª mode de retour orthographique)
* **sra5 â€“g** **sra5** active une nouvelle grammaire (sur un chemin local Ã  la machine)

# Annexe 2 - utiliser ppilot5

**ppilot5** permet dâ€™utiliser des systÃ¨mes de synthÃ¨se vocale compatibles SAPI5.

**Lancement de lâ€™agent**

ppilot5 -b 127.255.255.255:2010 -r Hortense -o "Microsoft Hortense"

**Par dÃ©faut, ppilot5 utilise le premier moteur de TTS trouvÃ© et apparaÃ®t sur le bus ivy sous le nom Â«Â ppilot5Â Â»**

**-b** adresse IP + port

**-r** nom sous lequel apparaÃ®tra lâ€™agent sous ivy (dans lâ€™exemple prÃ©cÃ©dent, Â«Â *Hortense*Â Â»)

**-o** nom du moteur de synthÃ¨se utilisÃ© (ici, la TTS "*Microsoft Hortense*", TTS par dÃ©faut sous windows)

**Commandes (UNIQUEMENT sur le bus ivy)**

***\* SynthÃ¨se***

* **ppilot5 Say=**hello **ppilot5** prononce via la TTS utilisÃ©e la chaÃ®ne de caractÃ¨res "hello"
* **ppilot5 SaySSML=***<sequence\_SSML>* **ppilot5** prononce la sÃ©quence SSML et renvoie **ppilot5 Answer=Finished** quand le buffer est vide. Les balises *<speak>* et *</speak>* sont automatiquement ajoutÃ©es au flux
  *Exemple de sÃ©quence SSML :*

ppilot5 SaySSML=Je peux parler <emphasis level="strong">trÃ¨s fort</emphasis> si je veux !

***\* Commandes***

* **ppilot5 Command=Stop** la synthÃ¨se vocale est stoppÃ©e. **ppilot5** renvoie **ppilot Answer=Stopped**
* **ppilot5 Command=Pause** la synthÃ¨se vocale est mise en pause. **ppilot5** renvoie **ppilot5 Answer=Paused**
* **ppilot5 Command=Resume** la synthÃ¨se vocale est relancÃ©e si elle Ã©tait en pause prÃ©cÃ©demment. **ppilot5** renvoie **ppilot5** **Answer=Resumed**
* **ppilot5 Command=Quit** lâ€™application se ferme

***\* ParamÃ¨tres***

* **ppilot5 Param=Pitch:**value le pitch est changÃ© par la valeur donnÃ©e. **ppilot5** renvoie **ppilot5 Answer=PitchValueSet:value**
* **ppilot5 Param=Speed:**value la vitesse est changÃ©e par la valeur donnÃ©e. **ppilot5** renvoie **ppilot5 Answer=SpeedValueSet:value**
* **ppilot5 Param=Volume:**value le volume est changÃ© par la valeur donnÃ©e. **ppilot5** renvoie **ppilot5 Answer=VolumeValueSet:value**

